# Modern Data Stack - Production Ready
# All port conflicts resolved, all configs included

services:
  # PostgreSQL - OLTP Database
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      POSTGRES_DB: finkit
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin123
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-sql:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - data-stack
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d finkit"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # MinIO - S3-Compatible Object Storage
  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"    # API
      - "9001:9001"    # Console
    command: server /data --console-address ":9001"
    networks:
      - data-stack
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped

  # Kafka Infrastructure
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - data-stack
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
    ports:
      - "9092:9092"
    networks:
      - data-stack
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    container_name: schema-registry
    depends_on:
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    ports:
      - "8081:8081"
    networks:
      - data-stack
    restart: unless-stopped

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
      - schema-registry
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_SCHEMAREGISTRY=http://schema-registry:8081
    ports:
      - "8080:8080"
    networks:
      - data-stack
    restart: unless-stopped

  # Apache Flink - Stream Processing
  flink-jobmanager:
    image: flink:1.18-scala_2.12
    container_name: flink-jobmanager
    ports:
      - "8082:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        parallelism.default: 2
    networks:
      - data-stack
    restart: unless-stopped

  flink-taskmanager:
    image: flink:1.18-scala_2.12
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
        parallelism.default: 2
    networks:
      - data-stack
    restart: unless-stopped

  # Apache Pinot - Real-time OLAP (FIXED PORTS)
  pinot-zookeeper:
    image: zookeeper:3.8.1
    container_name: pinot-zookeeper
    ports:
      - "2182:2181"  # Different port to avoid conflict
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - data-stack

  pinot-controller:
    image: apachepinot/pinot:latest
    container_name: pinot-controller
    command: "StartController -zkAddress pinot-zookeeper:2181"
    depends_on:
      - pinot-zookeeper
    ports:
      - "9002:9000"    # FIXED: Use port 9002
    networks:
      - data-stack
    restart: unless-stopped

  pinot-broker:
    image: apachepinot/pinot:latest
    container_name: pinot-broker
    command: "StartBroker -zkAddress pinot-zookeeper:2181"
    depends_on:
      - pinot-controller
    ports:
      - "8099:8099"
    networks:
      - data-stack
    restart: unless-stopped

  pinot-server:
    image: apachepinot/pinot:latest
    container_name: pinot-server
    command: "StartServer -zkAddress pinot-zookeeper:2181"
    depends_on:
      - pinot-broker
    networks:
      - data-stack
    restart: unless-stopped

  # Trino - Federated Query Engine (WITH CONFIG)
  trino:
    image: trinodb/trino:latest
    container_name: trino
    ports:
      - "8083:8080"
    volumes:
      - ./trino-config:/etc/trino
    networks:
      - data-stack
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped


  # Airflow Services
  airflow-postgres:
    image: postgres:15-alpine
    container_name: airflow-postgres
    environment:
      POSTGRES_DB: airflow
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow123
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    tmpfs:
      - /opt/airflow/logs
      - /opt/airflow/dags/__pycache__
    networks:
      - data-stack

  airflow-redis:
    image: redis:7-alpine
    container_name: airflow-redis
    networks:
      - data-stack

  airflow-webserver:
    image: apache/airflow:2.7.1
    container_name: airflow-webserver
    depends_on:
      - airflow-postgres
      - airflow-redis
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow123@airflow-postgres:5432/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow123@airflow-postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://airflow-redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSHMpQfKBf6cWC8iD_vBQ3Kf8h8A=
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin123
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPYCACHEPREFIX=/tmp/pycache
    volumes:
      - ./airflow/dags:/opt/airflow/dags      
      - ./airflow/plugins:/opt/airflow/plugins
    tmpfs:
      - /opt/airflow/logs
      - /opt/airflow/dags/__pycache__
    ports:
      - "8084:8080"
    command: webserver
    networks:
      - data-stack
    restart: unless-stopped

  airflow-scheduler:
    image: apache/airflow:2.7.1
    container_name: airflow-scheduler
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow123@airflow-postgres:5432/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow123@airflow-postgres:5432/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://airflow-redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSHMpQfKBf6cWC8iD_vBQ3Kf8h8A=
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/plugins:/opt/airflow/plugins     
    tmpfs:
      - /opt/airflow/logs
      - /opt/airflow/dags/__pycache__
    command: scheduler
    networks:
      - data-stack
    restart: unless-stopped

  # Metabase - Business Intelligence
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    ports:
      - "3000:3000"
    environment:
      - MB_DB_TYPE=postgres
      - MB_DB_DBNAME=metabase
      - MB_DB_PORT=5432
      - MB_DB_USER=admin
      - MB_DB_PASS=admin123
      - MB_DB_HOST=postgres
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - data-stack
    restart: unless-stopped

  # Jupyter - Data Science Notebook
  jupyter:
    image: jupyter/datascience-notebook:latest
    container_name: jupyter
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=admin123
    volumes:
      - ./notebooks:/home/jovyan/work
      - jupyter_data:/home/jovyan
    networks:
      - data-stack
    restart: unless-stopped

  # SQL Mesh - Data Mesh Engine
  sqlmesh:
    build:
      context: ./sqlmesh
      dockerfile: Dockerfile
    platform: linux/arm64
    container_name: sqlmesh
    volumes:
      - ./sqlmesh:/app
    ports:
      - "7600:7600"
    command: ["sqlmesh", "ui", "--host", "0.0.0.0", "--port", "7600"]
    networks:
      - data-stack
    restart: unless-stopped

volumes:
  postgres_data:
  minio_data:
  airflow_postgres_data:
  jupyter_data:

networks:
  data-stack:
    driver: bridge
